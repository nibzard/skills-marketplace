#!/usr/bin/env python3
"""
Agent tool: Extract patterns and relationships from HTTP responses
Analyzes response structure to infer application behavior
"""

import json
import sys
import urllib.request
import ssl
from typing import Dict, List, Any, Optional
import re
from collections import defaultdict, Counter

class ResponseAnalyzer:
    """
    Analyzes HTTP responses to extract patterns, relationships, and security indicators
    Designed for agent consumption (JSON output, no prompts)
    """

    def __init__(self):
        self.ssl_context = self._create_ssl_context()
        self.patterns = {
            'security_headers': [
                'x-frame-options', 'x-xss-protection', 'x-content-type-options',
                'strict-transport-security', 'content-security-policy',
                'x-content-security-policy', 'referrer-policy'
            ],
            'auth_indicators': [
                'authorization', 'bearer', 'token', 'jwt', 'session',
                'cookie', 'set-cookie', 'www-authenticate', 'api-key'
            ],
            'error_patterns': [
                r'error', r'exception', r'invalid', r'unauthorized',
                r'forbidden', r'not found', r'traceback', r'sql',
                r'database', r'server error'
            ],
            'data_relationships': [
                r'_id$', r'id$', r'_uid$', r'uuid', r'foreign_key',
                r'reference', r'parent_id', r'user_id', r'owner_id',
                r'team_id', r'project_id'
            ]
        }

    def _create_ssl_context(self):
        """Create SSL context for HTTPS requests"""
        ctx = ssl.create_default_context()
        ctx.check_hostname = False
        ctx.verify_mode = ssl.CERT_NONE
        return ctx

    def analyze_response(self, response_data: Dict[str, Any]) -> Dict[str, Any]:
        """Analyze a single HTTP response"""
        analysis = {
            'url': response_data.get('url', ''),
            'status_code': response_data.get('status', 0),
            'headers_analysis': self._analyze_headers(response_data.get('headers', {})),
            'content_analysis': self._analyze_content(response_data.get('content', ''), response_data.get('content_type', '')),
            'security_indicators': self._assess_security(response_data),
            'data_patterns': self._extract_data_patterns(response_data.get('content', ''), response_data.get('content_type', ''))
        }

        return analysis

    def _analyze_headers(self, headers: Dict[str, str]) -> Dict[str, Any]:
        """Analyze HTTP headers for patterns and security"""
        analysis = {
            'security_headers_present': [],
            'security_headers_missing': [],
            'auth_indicators': [],
            'server_info': {},
            'interesting_headers': []
        }

        # Lowercase header keys for case-insensitive matching
        lower_headers = {k.lower(): v for k, v in headers.items()}

        # Check security headers
        for security_header in self.patterns['security_headers']:
            if security_header in lower_headers:
                analysis['security_headers_present'].append({
                    'name': security_header,
                    'value': lower_headers[security_header]
                })
            else:
                analysis['security_headers_missing'].append(security_header)

        # Look for authentication indicators
        for auth_indicator in self.patterns['auth_indicators']:
            for header_name in lower_headers:
                if auth_indicator in header_name.lower() or auth_indicator in lower_headers[header_name].lower():
                    analysis['auth_indicators'].append({
                        'header': header_name,
                        'value': lower_headers[header_name][:100] + '...' if len(lower_headers[header_name]) > 100 else lower_headers[header_name]
                    })

        # Extract server information
        if 'server' in lower_headers:
            analysis['server_info']['server'] = lower_headers['server']
        if 'x-powered-by' in lower_headers:
            analysis['server_info']['powered_by'] = lower_headers['x-powered-by']
        if 'x-generator' in lower_headers:
            analysis['server_info']['generator'] = lower_headers['x-generator']

        # Interesting headers for security analysis
        interesting_patterns = ['access-control', 'cors', 'cache', 'etag', 'last-modified']
        for header_name, value in lower_headers.items():
            if any(pattern in header_name.lower() for pattern in interesting_patterns):
                analysis['interesting_headers'].append({
                    'name': header_name,
                    'value': value
                })

        return analysis

    def _analyze_content(self, content: str, content_type: str) -> Dict[str, Any]:
        """Analyze response content"""
        analysis = {
            'content_type': content_type,
            'size': len(content),
            'content_classification': 'unknown',
            'data_structure': {},
            'error_indicators': [],
            'form_fields': [],
            'links_and_endpoints': []
        }

        # Classify content type
        if 'json' in content_type.lower():
            analysis['content_classification'] = 'json'
            analysis['data_structure'] = self._analyze_json_content(content)
        elif 'html' in content_type.lower():
            analysis['content_classification'] = 'html'
            analysis['data_structure'] = self._analyze_html_content(content)
        elif 'xml' in content_type.lower():
            analysis['content_classification'] = 'xml'
            analysis['data_structure'] = self._analyze_xml_content(content)
        else:
            analysis['content_classification'] = 'text'
            analysis['data_structure'] = self._analyze_text_content(content)

        # Look for error indicators
        for pattern in self.patterns['error_patterns']:
            matches = re.findall(pattern, content, re.IGNORECASE)
            if matches:
                analysis['error_indicators'].extend(matches)

        # Extract form fields (for HTML content)
        if 'html' in content_type.lower():
            analysis['form_fields'] = self._extract_form_fields(content)

        # Extract links and endpoints
        analysis['links_and_endpoints'] = self._extract_links(content)

        return analysis

    def _analyze_json_content(self, content: str) -> Dict[str, Any]:
        """Analyze JSON content structure"""
        try:
            data = json.loads(content)
            return self._analyze_json_structure(data)
        except json.JSONDecodeError:
            return {'error': 'Invalid JSON', 'raw_content_preview': content[:200]}

    def _analyze_json_structure(self, data: Any, depth: int = 0, max_depth: int = 5) -> Dict[str, Any]:
        """Recursively analyze JSON structure"""
        if depth > max_depth:
            return {'type': 'max_depth_reached'}

        if isinstance(data, dict):
            structure = {
                'type': 'object',
                'field_count': len(data),
                'fields': {},
                'relationships': [],
                'sensitive_fields': []
            }

            for key, value in data.items():
                field_info = {
                    'type': type(value).__name__,
                    'nested_structure': self._analyze_json_structure(value, depth + 1, max_depth) if isinstance(value, (dict, list)) else None
                }

                # Identify potential relationships
                for relationship_pattern in self.patterns['data_relationships']:
                    if re.search(relationship_pattern, key, re.IGNORECASE):
                        structure['relationships'].append({
                            'field': key,
                            'pattern': relationship_pattern,
                            'value_type': type(value).__name__
                        })

                # Identify potentially sensitive fields
                sensitive_patterns = ['password', 'token', 'secret', 'key', 'auth', 'private', 'confidential']
                if any(sensitive in key.lower() for sensitive in sensitive_patterns):
                    structure['sensitive_fields'].append({
                        'field': key,
                        'type': type(value).__name__
                    })

                structure['fields'][key] = field_info

            return structure

        elif isinstance(data, list):
            return {
                'type': 'array',
                'length': len(data),
                'item_types': list(set(type(item).__name__ for item in data[:10])),  # Sample first 10 items
                'sample_structure': self._analyze_json_structure(data[0], depth + 1, max_depth) if data else None
            }

        else:
            return {
                'type': type(data).__name__,
                'value_preview': str(data)[:100] + '...' if len(str(data)) > 100 else str(data)
            }

    def _analyze_html_content(self, content: str) -> Dict[str, Any]:
        """Analyze HTML content structure"""
        structure = {
            'type': 'html',
            'forms': [],
            'scripts': [],
            'links': [],
            'meta_tags': [],
            'input_fields': []
        }

        # Extract forms
        form_matches = re.findall(r'<form[^>]*>(.*?)</form>', content, re.DOTALL | re.IGNORECASE)
        for i, form_content in enumerate(form_matches):
            inputs = re.findall(r'<input[^>]*>', form_content, re.IGNORECASE)
            structure['forms'].append({
                'index': i,
                'input_count': len(inputs),
                'inputs': [{'tag': inp} for inp in inputs[:5]]  # Sample first 5 inputs
            })

        # Extract scripts
        script_matches = re.findall(r'<script[^>]*src=["\']([^"\']+)["\']', content, re.IGNORECASE)
        structure['scripts'] = script_matches[:10]  # Sample first 10

        # Extract meta tags
        meta_matches = re.findall(r'<meta[^>]*>', content, re.IGNORECASE)
        structure['meta_tags'] = meta_matches[:10]  # Sample first 10

        return structure

    def _analyze_xml_content(self, content: str) -> Dict[str, Any]:
        """Analyze XML content structure"""
        # Simple XML analysis
        tags = re.findall(r'<([^>]+)>', content)
        return {
            'type': 'xml',
            'unique_tags': list(set(tags)),
            'tag_count': len(tags),
            'root_elements': [tag for tag in tags if not tag.startswith('/')]
        }

    def _analyze_text_content(self, content: str) -> Dict[str, Any]:
        """Analyze plain text content"""
        words = content.split()
        return {
            'type': 'text',
            'word_count': len(words),
            'line_count': content.count('\n') + 1,
            'contains_urls': len(re.findall(r'https?://[^\s]+', content)),
            'contains_emails': len(re.findall(r'\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\.[A-Z|a-z]{2,}\b', content))
        }

    def _extract_form_fields(self, content: str) -> List[Dict[str, Any]]:
        """Extract form fields from HTML content"""
        input_pattern = r'<input[^>]*name=["\']([^"\']*)["\'][^>]*(?:type=["\']([^"\']*)["\'])?[^>]*>'
        inputs = re.findall(input_pattern, content, re.IGNORECASE)

        fields = []
        for name, input_type in inputs:
            fields.append({
                'name': name,
                'type': input_type or 'text',
                'sensitive': any(pattern in name.lower() for pattern in ['password', 'secret', 'key', 'token'])
            })

        return fields

    def _extract_links(self, content: str) -> List[str]:
        """Extract links and potential endpoints"""
        # URL patterns
        url_patterns = [
            r'https?://[^\s"\'<>]+',
            r'["\'](/[^"\']*)["\']',  # Relative URLs
            r'action=["\']([^"\']*)["\']',  # Form actions
            r'href=["\']([^"\']*)["\']',  # Links
        ]

        all_links = []
        for pattern in url_patterns:
            matches = re.findall(pattern, content, re.IGNORECASE)
            all_links.extend(matches)

        # Remove duplicates and filter
        unique_links = list(set(link for link in all_links if link and len(link) > 2))
        return unique_links[:20]  # Return first 20 links

    def _extract_data_patterns(self, content: str, content_type: str) -> Dict[str, Any]:
        """Extract data patterns and relationships"""
        patterns = {
            'ids_and_references': [],
            'timestamps': [],
            'status_fields': [],
            'business_entities': [],
            'data_relationships': []
        }

        # Look for ID patterns
        id_patterns = [
            r'"([^"]*_?id[^"]*)"\s*:\s*["\']?([^"\'\s,}]+)',  # JSON id fields
            r'(\w+_id)\s*[:=]',  # Generic id references
            r'([a-f0-9-]{36})',  # UUIDs
        ]

        for pattern in id_patterns:
            matches = re.findall(pattern, content, re.IGNORECASE)
            for match in matches:
                if isinstance(match, tuple):
                    patterns['ids_and_references'].append({
                        'field': match[0],
                        'value': match[1]
                    })
                else:
                    patterns['ids_and_references'].append({'value': match})

        # Look for timestamps
        timestamp_patterns = [
            r'\d{4}-\d{2}-\d{2}[T ]\d{2}:\d{2}:\d{2}',  # ISO timestamps
            r'\d{10,13}',  # Unix timestamps
        ]

        for pattern in timestamp_patterns:
            matches = re.findall(pattern, content)
            patterns['timestamps'].extend(matches[:10])  # Sample first 10

        # Look for status fields
        status_patterns = [
            r'"status"\s*:\s*"([^"]+)"',
            r'"state"\s*:\s*"([^"]+)"',
            r'"active"\s*:\s*(true|false)',
        ]

        for pattern in status_patterns:
            matches = re.findall(pattern, content, re.IGNORECASE)
            patterns['status_fields'].extend(matches)

        return patterns

    def _assess_security(self, response_data: Dict[str, Any]) -> Dict[str, Any]:
        """Assess security aspects of the response"""
        security_assessment = {
            'information_disclosure': [],
            'authentication_required': False,
            'authorization_present': False,
            'session_management': [],
            'security_headers_score': 0,
            'vulnerability_indicators': []
        }

        status = response_data.get('status', 0)
        headers = response_data.get('headers', {})
        content = response_data.get('content', '')

        # Information disclosure indicators
        if status == 500:
            if 'traceback' in content.lower() or 'exception' in content.lower():
                security_assessment['information_disclosure'].append('stack_trace_exposed')
            if 'sql' in content.lower() and 'error' in content.lower():
                security_assessment['information_disclosure'].append('sql_error_exposed')

        # Authentication/authorization indicators
        if status == 401:
            security_assessment['authentication_required'] = True
        elif status == 403:
            security_assessment['authorization_present'] = True

        # Session management
        session_indicators = ['session', 'token', 'jwt', 'cookie']
        for indicator in session_indicators:
            if indicator in content.lower() or any(indicator in header.lower() for header in headers):
                security_assessment['session_management'].append(indicator)

        # Security headers scoring
        security_headers_found = sum(1 for header in self.patterns['security_headers']
                                   if header.lower() in [h.lower() for h in headers.keys()])
        security_assessment['security_headers_score'] = security_headers_found / len(self.patterns['security_headers'])

        # Potential vulnerability indicators
        vuln_patterns = [
            (r'debug\s*=\s*true', 'debug_mode_enabled'),
            (r'version\s*[:=]\s*["\']?([^"\'\s]+)', 'version_disclosed'),
            (r'password\s*[:=]', 'password_parameter_exposed'),
        ]

        for pattern, indicator in vuln_patterns:
            matches = re.findall(pattern, content, re.IGNORECASE)
            if matches:
                security_assessment['vulnerability_indicators'].append(indicator)

        return security_assessment

    def analyze_multiple_responses(self, responses: List[Dict[str, Any]]) -> Dict[str, Any]:
        """Analyze multiple responses and extract cross-response patterns"""
        individual_analyses = [self.analyze_response(resp) for resp in responses]

        cross_analysis = {
            'individual_analyses': individual_analyses,
            'cross_response_patterns': self._find_cross_response_patterns(individual_analyses),
            'common_data_structures': self._find_common_data_structures(individual_analyses),
            'security_summary': self._summarize_security(individual_analyses),
            'endpoints_analysis': self._analyze_endpoints(individual_analyses)
        }

        return cross_analysis

    def _find_cross_response_patterns(self, analyses: List[Dict[str, Any]]) -> Dict[str, Any]:
        """Find patterns across multiple responses"""
        patterns = {
            'common_status_codes': Counter(analysis['status_code'] for analysis in analyses),
            'common_content_types': Counter(analysis['content_analysis']['content_type'] for analysis in analyses),
            'shared_data_fields': self._find_shared_data_fields(analyses),
            'common_error_patterns': [],
            'authentication_flow_detected': False
        }

        # Find shared data fields
        data_structures = [analysis['data_patterns'] for analysis in analyses]
        all_ids = []
        for structure in data_structures:
            all_ids.extend([id_ref['field'] if 'field' in id_ref else 'unknown' for id_ref in structure.get('ids_and_references', [])])

        if all_ids:
            patterns['shared_data_fields'] = Counter(all_ids).most_common(10)

        # Check for authentication flow
        status_codes = [analysis['status_code'] for analysis in analyses]
        if 200 in status_codes and (401 in status_codes or 403 in status_codes):
            patterns['authentication_flow_detected'] = True

        return patterns

    def _find_common_data_structures(self, analyses: List[Dict[str, Any]]) -> Dict[str, Any]:
        """Find common data structures across responses"""
        common_structures = {
            'object_types': Counter(),
            'field_patterns': Counter(),
            'data_relationships': []
        }

        for analysis in analyses:
            content_analysis = analysis.get('content_analysis', {})
            data_structure = content_analysis.get('data_structure', {})

            if isinstance(data_structure, dict):
                if data_structure.get('type') == 'object':
                    common_structures['object_types'].update(data_structure.get('fields', {}).keys())

        return common_structures

    def _summarize_security(self, analyses: List[Dict[str, Any]]) -> Dict[str, Any]:
        """Summarize security findings across responses"""
        summary = {
            'average_security_headers_score': 0,
            'total_vulnerability_indicators': 0,
            'information_disclosure_instances': 0,
            'authentication_endpoints': 0,
            'authorization_endpoints': 0
        }

        security_scores = []
        vulnerability_count = 0
        disclosure_count = 0
        auth_count = 0
        authz_count = 0

        for analysis in analyses:
            security = analysis.get('security_indicators', {})

            security_scores.append(security.get('security_headers_score', 0))
            vulnerability_count += len(security.get('vulnerability_indicators', []))
            disclosure_count += len(security.get('information_disclosure', []))

            if security.get('authentication_required'):
                auth_count += 1
            if security.get('authorization_present'):
                authz_count += 1

        if security_scores:
            summary['average_security_headers_score'] = sum(security_scores) / len(security_scores)

        summary['total_vulnerability_indicators'] = vulnerability_count
        summary['information_disclosure_instances'] = disclosure_count
        summary['authentication_endpoints'] = auth_count
        summary['authorization_endpoints'] = authz_count

        return summary

    def _analyze_endpoints(self, analyses: List[Dict[str, Any]]) -> Dict[str, Any]:
        """Analyze endpoint characteristics"""
        endpoints = []

        for analysis in analyses:
            endpoint_info = {
                'url': analysis['url'],
                'status_code': analysis['status_code'],
                'content_type': analysis['content_analysis']['content_type'],
                'response_size': analysis['content_analysis']['size'],
                'has_authentication': analysis['security_indicators']['authentication_required'],
                'has_authorization': analysis['security_indicators']['authorization_present']
            }
            endpoints.append(endpoint_info)

        return {
            'total_endpoints': len(endpoints),
            'endpoint_details': endpoints,
            'status_code_distribution': Counter(ep['status_code'] for ep in endpoints),
            'content_type_distribution': Counter(ep['content_type'] for ep in endpoints)
        }


def main():
    """CLI interface for agent use"""
    if len(sys.argv) < 2:
        print("Usage: python analyze_responses.py <response_json_file> [multiple_responses]", file=sys.stderr)
        print("Output: JSON analysis to stdout", file=sys.stderr)
        sys.exit(1)

    input_file = sys.argv[1]
    multiple_mode = len(sys.argv) > 2 and sys.argv[2] == "multiple"

    try:
        with open(input_file, 'r') as f:
            data = json.load(f)
    except Exception as e:
        print(f"Error reading input file: {e}", file=sys.stderr)
        sys.exit(1)

    analyzer = ResponseAnalyzer()

    if multiple_mode:
        if isinstance(data, list):
            analysis = analyzer.analyze_multiple_responses(data)
        else:
            print("Expected array of response objects for multiple mode", file=sys.stderr)
            sys.exit(1)
    else:
        analysis = analyzer.analyze_response(data)

    # Output JSON to stdout for agent consumption
    print(json.dumps(analysis, indent=2))


if __name__ == "__main__":
    main()